<!DOCTYPE html>
<html lang="en">


<head>

   <meta charset="UTF-8">
   <meta name="description" content="Ethical Challenges in Technology">
   <meta name="author" content="Sarah Snow & Emily Nguyen">
   <meta name="viewport" content="">
   <title>Ethical Tech</title>

   <!-- Links -->
   <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-Piv4xVNRyMGpqkS2by6br4gNJ7DXjqk09RmUpJ8jgGtD7zP9yug3goQfGII0yAns"
      crossorigin="anonymous"></script>
   <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css"
      integrity="sha384-B0vP5xmATw1+K9KRQjQERJvTumQW0nPEzvF6L/Z6nronJ3oUOFUFpCjEUQouq2+l" crossorigin="anonymous">

</head>

<body>
   <p><strong>Course Description</strong></p>
   <p><em>Ethical Challenges in Technology</em> is a high-level overview of ethical issues within the technology
      industry. Specific course topics will include current event analysis and case studies of landmark events in the
      history of computing. Students will analyze particular products and policies that have fundamentally impacted the
      course of the industry. The course will be primarily discussion-based, with a semester-long project and weekly
      reflection posts. Students will find that many of the course topics are relevant to other UVA computer science
      curriculum classes. This structure will allow students to combine existing knowledge with a broad perspective on
      how these technologies affect the larger industry. </p>
   <p><strong>Course Logistics</strong></p>
   <ul>
      <li>
         <p>There are 12 weeks of planned course material. </p>
      </li>
      <li>
         <p>The course will meet Monday, Wednesday, and Friday from 2:00-2:50 pm. </p>
      </li>
      <li>
         <p>Class meetings will be online and synchronous via Zoom on UVA Collab. </p>
      </li>
      <li>
         <p>In-class discussions and office hours will utilize a class Discord server.</p>
      </li>
      <li>
         <p>This is a discussion-based course, and attendance is required.</p>
         <p><em>Note: Students will not be penalized for any unavoidable absence but should notify course staff and
               discussion group members ahead of time, if possible.</em> </p>
      </li>

   </ul>
   <p><strong>Learning Goals</strong></p>
   <p>By the end of the course, students should:</p>
   <ul>
      <li>understand and articulate critical perspectives of computing technologies</li>
      <li>recognize the importance of ethical considerations in software development</li>
      <li>assess the social implications of their specific career goals</li>
      <li>respect diverse opinions and engage in difficult conversations</li>
      <li>evaluate the ethical responsibilities of individuals and organizations</li>

   </ul>
   <p><strong>Prerequisites</strong></p>
   <ul>
      <li>While there are no specific pre-requisite courses, fourth-year Computer Science majors will be prioritized for
         registration. One week after enrollment registration begins, the course will open to all students. </li>
      <li>Come to class with an open mind! Students should be prepared to engage in difficult and sensitive topics of
         discussion while maintaining respect for other students’ perspectives and ideas. </li>

   </ul>
   <p><strong>Communications </strong></p>
   <ul>
      <li>
         <p><em>Collab</em> will be used for:</p>
         <ul>
            <li>lectures held on the Online Meetings page</li>
            <li>project materials submitted to the Assignments page</li>
            <li>assignment grades released to the Gradebook page</li>

         </ul>
      </li>
      <li>
         <p><em>Discord</em> will be used for:</p>
         <ul>
            <li>all students are expected to join the class server!</li>
            <li>informal lecture chats on topic-specific channels</li>
            <li>private discussion group chats</li>
            <li>office hours in private voice rooms</li>

         </ul>
      </li>
      <li>
         <p><em>This Webpage</em> will be used for:</p>
         <ul>
            <li>up-to-date information on course topics and schedules</li>
            <li>assignment descriptions and deadlines</li>
            <li>links to readings and other relevant materials</li>

         </ul>
      </li>
      <li>
         <p><em>GitHub</em> will be used for:</p>
         <ul>
            <li>discussion forum instructions and submissions</li>

         </ul>
      </li>
      <li>
         <p><em>Email</em> will be used for: </p>
         <ul>
            <li>important course-wide emails</li>
            <li>personal administrative inquiries</li>
            <li>notice of unavoidable absences</li>

         </ul>
      </li>

   </ul>
   <p><strong>Coursework</strong></p>
   <p><em>Project</em></p>
   <p>Throughout the semester, students will engage in a self-guided project consisting of three major parts: project
      proposal, written deliverable, and presentation. Students will have the chance to work alone or with one
      additional person on the project. There will be a discussion page for students to share their project ideas and
      find a partner.</p>
   <p><em>Discussion Forum</em></p>
   <p>Every week students will post in an online discussion forum to reflect on the week’s topic or case study.
      Discussion forum posts are due _before _class. No late submissions will be accepted, but students will be able to
      participate in a make-up discussion at the end of the semester. </p>
   <ul>
      <li>
         <p><em>Pre-Discussion (must be posted before Monday class)</em></p>
         <ul>
            <li>
               <p>Students should reflect generally on the assigned readings for Monday’s class and their general
                  expectations regarding the topic. Additional topic-specific reflection questions will be posted on the
                  discussion page.</p>
               <ul>
                  <li>Are there any specific aspects of the issue that you would like to further explore? </li>
                  <li>Can you identify any perspectives that are missing from the sources?</li>
                  <li>What types of additional sources would help to clarify this issue?</li>
                  <li>What surprised you the most about the initial readings?</li>
                  <li>Has this issue impacted your personal experience in computing?</li>

               </ul>
            </li>

         </ul>
      </li>
      <li>
         <p><em>Post-Discussion (must be posted before Friday class)</em></p>
         <ul>
            <li>
               <p>Students should reflect on how their perspective on the topic has changed based on the case studies
                  and discussion groups. Additional topic-specific questions will be posted on the discussion page.</p>
               <ul>
                  <li>How has your perspective changed since the pre-reading?</li>
                  <li>Did any specific discussion in your breakout groups have a significant impact on your
                     understanding of this issue?</li>
                  <li>Going forward, do you expect this issue to impact your personal experience?</li>
                  <li>What surprised you the most about this topic?</li>

               </ul>
            </li>

         </ul>
      </li>

   </ul>
   <p><strong>Participation and Professionalism</strong></p>
   <p>In order to help facilitate discussions, breakout sessions will be conducted at various times throughout the
      course. Students will rotate through four different randomly assigned discussion groups. The size of discussion
      groups will depend on overall course enrollment but you can expect 4 - 6 students per group. Each discussion group
      will meet for a three-week period, after which the students will reflect on their experiences and evaluate their
      fellow group members. The participation and professionalism grade will be based on group evaluations, attendance,
      and overall engagement. For unavoidable absences, students should notify their discussion group by email and cc
      the course instructor for visibility. Students are expected to respect the opinions of others and abide by
      pre-established group norms. </p>
   <p><strong>Current Event Talks</strong></p>
   <p>Each student will be expected to sign-up for a five-minute lightning talk on a current event. Throughout the
      semester, students will present the talks at the end of class on Friday. Specific materials are not required, but
      the talks are expected to be engaging and informative. For full credit, students will be required to post a brief
      summary of their talk (with links to sources) on the discussion page. There is no specific length requirement, but
      a sufficient summarization is expected to be around 500 words. Current events are expected to be relevant to any
      of the themes covered in the course and should be taken from a primary source published during the week of the
      talk. </p>
   <p><strong>Self-Care</strong></p>
   <p>Online school can be very challenging for students (and course staff) and we recognize that the lack of
      face-to-face interaction can have various negative impacts. Throughout the semester, students will be encouraged
      to spend some time on wellness. Students will reflect on their progress during a bi-weekly judgment-free survey.
      There will be a chance to give anonymous feedback to course staff and request additional support if needed. </p>
   <p><strong>Grading</strong></p>
   <ul>
      <li>
         <p>Project (30%)</p>
         <ul>
            <li>Project Proposal (5%)</li>
            <li>Written Deliverable (15%)</li>
            <li>Presentation (10%)</li>

         </ul>
      </li>
      <li>
         <p>Discussion Forum (30%)</p>
      </li>
      <li>
         <p>Participation and Professionalism (20%)</p>
      </li>
      <li>
         <p>Current Event Talk (10%)</p>
      </li>
      <li>
         <p>Self-Care (10%)</p>
      </li>

   </ul>
   <p><strong>Privacy and Anonymity</strong></p>
   <p>We will be using a private Discord server and the GitHub discussion feature throughout the course to facilitate
      office hours and discussion forums. If a student does not already have one (or both) of these accounts, they will
      be expected to make one. Both are free and do not require the use of your UVA email account. </p>
   <p>While Discord provides custom channels and the ability to privately chat with other students, it does not allow
      for threaded conversations and is unsuitable for discussion forums. The GitHub discussion site is publicly visible
      but will be taken down at the conclusion of the course. Students with privacy concerns are encouraged to make a
      new GitHub account with a pseudonym that is not connected to any existing online identities. Students who choose
      to use a pseudonym should notify course staff by email in order to get credit for grading purposes. </p>
   <p><strong>Academic Integrity</strong></p>
   <p>We trust every student in this course to fully comply with all of the provisions of the University’s Honor Code.
      By enrolling in this course, you have agreed to abide by and uphold the Honor System of the University of
      Virginia, as well as the following policies specific to this course.</p>
   <ul>
      <li>All graded assignments must be pledged</li>
      <li>Students are allowed to collaborate with up to one other student on the project</li>
      <li>Work by another person should be cited properly when necessary</li>

   </ul>
   <p><strong>SDAC Accommodations</strong></p>
   <p>The University of Virginia strives to provide accessibility to all students. If you require accommodation to fully
      access this course, please contact the Student Disability Access Center (SDAC) at (434) 243-5180 or <a
         href='mailto:sdac@virginia.edu' target='_blank' class='url'>sdac@virginia.edu</a>. If you are unsure if you
      require an accommodation, or to learn more about their services, you may contact the SDAC at the number above or
      by visiting their website <a href='https://studenthealth.virginia.edu/sdac' target='_blank'
         class='url'>https://studenthealth.virginia.edu/sdac</a></p>
   <p><strong>Religious Accommodations</strong></p>
   <p>Students who wish to request academic accommodation for a religious observance should submit their request to me
      by email as far in advance as possible. If you have questions or concerns about your request, you can contact the
      University’s Office for Equal Opportunity and Civil Rights (EOCR) at <a href='mailto:UVAEOCR@virginia.edu'
         target='_blank' class='url'>UVAEOCR@virginia.edu</a> or 434-924-3200. Accommodations do not relieve you of the
      responsibility for completion of any part of the coursework you miss as the result of a religious observance.</p>
   <p><strong>Additional Support</strong></p>
   <p>If you are feeling overwhelmed, stressed, or isolated, there are many individuals here who are ready and wanting
      to help. The Student Health Center offers Counseling and Psychological Services (CAPS) for all UVA students. Call
      434-243-5150 (or 434-972-7004 for after-hours and weekend crisis assistance) to get started and schedule an
      appointment. If you prefer to speak anonymously and confidentially over the phone, Madison House provides a HELP
      Line at any hour of any day: 434-295-8255.</p>
   <p><strong>Schedule</strong></p>
   <p><strong>Introduction</strong></p>
   <p>Week 1</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Introductions!
               </p>
               <p>
                  Learning Objectives
               </p>
               <p>
                  Expectations
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  None!
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Introductions</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 1</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><strong>Unit 1: Algorithmic Bias</strong></p>
   <p>Week 2</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 2</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 2</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p>Week 3</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Watch “<a href="https://www.pbs.org/independentlens/videos/coded-bias-trailer/">Coded Bias</a>” film
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.vice.com/en/article/n7v8mx/coded-bias-netflix-documentary-ai-ethics-surveil">'Coded
                     Bias' Is the Most Important Film About AI You Can Watch Today</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 3</em></strong>
               </p>
               <p>
                  <strong><em>TODO: Finish “Coded Bias”</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Discuss Film
               </p>
               <p>
                  Solutions (?)
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a
                     href="https://www.technologyreview.com/2019/02/04/137602/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/">This
                     is how AI bias really happens—and why it’s so hard to fix</a>
               </p>
               <p>
                  <a
                     href="https://www.vox.com/future-perfect/2019/4/19/18412674/ai-bias-facial-recognition-black-gay-transgender">Some
                     AI just shouldn’t exist</a>
               </p>
               <p>
                  <a
                     href="https://www.wyden.senate.gov/imo/media/doc/Algorithmic%20Accountability%20Act%20of%202019%20Bill%20Text.pdf">Algorithmic
                     Accountability Act</a>
               </p>
               <p>
                  <a href="https://www.ibm.com/blogs/research/2018/06/ai-facial-analytics/">IBM to release world’s
                     largest annotation dataset for studying bias in facial analysis</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Changes + Efforts
               </p>
               <p>
                  Current Event Chat
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a
                     href="https://medium.com/@Joy.Buolamwini/ibm-leads-more-should-follow-racial-justice-requires-algorithmic-justice-and-funding-da47e07e5b58">IBM
                     Leads, More Should Follow: Racial Justice Requires Algorithmic Justice</a>
               </p>
               <p>
                  <a href="https://ainowinstitute.org/discriminatingsystems.pdf">Discriminating Systems</a>
               </p>
               <p>
                  <a href="https://cyber.harvard.edu/sites/default/files/2019-10/2019AIAlgorithmsJusticeOnePager.pdf">Algorithms
                     and Justice</a>
               </p>
               <p>
                  <a
                     href="https://global-uploads.webflow.com/5e027ca188c99e3515b404b7/5e332b739c247f30b4888385_AJL%20101%20Final%20_1.22.20.pdf">Algorithmic
                     Justice League</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 3</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><em>* Submit Evaluation of Discussion Group #1 *</em></p>
   <p><strong>Unit 2: Automation</strong></p>
   <p>Week 4</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 4</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 4</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><strong>Unit 3: Gig Economy</strong></p>
   <p>Week 5</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 5</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 5</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><strong>Unit 4: Silicon Valley</strong></p>
   <p>Week 6</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 6</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 6</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <pre><code>_* Submit Evaluation of Discussion Group #2 *_
   </code></pre>
   <p><strong>Unit 5: Platforms</strong></p>
   <p>Week 7</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 7</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 7</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p>Week 8</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 8</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 8</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><strong>Unit 6: Regulation</strong></p>
   <p>Week 9</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shade</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 9</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 9</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><em>* Submit Evaluation of Discussion Group #3 *</em></p>
   <p><strong>Unit 7: Environment</strong></p>
   <p>Week 10</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 10</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 10</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><strong>Unit 8: Special Topics</strong></p>
   <p>Week 11</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 11</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 11</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p>Week 12</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: Week 12</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: Week 12</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>
   <p>&nbsp;</p>
   <p><em>* Submit Evaluation of Discussion Group #4 *</em></p>
   <p><strong>Wrap Up</strong></p>
   <p>Week 13</p>
   <table>
      <tbody>
         <tr>
            <td>Monday
            </td>
            <td>Wednesday
            </td>
            <td>Friday
            </td>
         </tr>
         <tr>
            <td><strong>Topic</strong>
               <p>
                  Gender Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.wired.com/story/artificial-intelligence-researchers-gender-imbalance/">AI Is the
                     Future—But Where Are the Women?</a>
               </p>
               <p>
                  <a
                     href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon
                     scraps secret AI recruiting tool that showed bias against women</a>
               </p>
               <p>
                  <a href="https://www.wired.com/story/the-apple-card-didnt-see-genderand-thats-the-problem/">The Apple
                     Card Didn't 'See' Gender—and That's the Problem</a>
               </p>
               <p>
                  <a href="http://gendershades.org">Gender Shades</a>
               </p>
               <p>
                  <strong><em>Pre-Discussion Forum: *Optional*</em></strong>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Racial Bias
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html">Who
                     Is Making Sure the A.I. Machines Aren’t Racist?</a>
               </p>
               <p>
                  <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">There’s
                     software used across the country to predict future criminals. And it’s biased against blacks.</a>
               </p>
               <p>
                  <a
                     href="https://www.nydailynews.com/news/national/ny-google-darker-skin-tones-facial-recognition-pixel-20191002-5vxpgowknffnvbmy5eg7epsf34-story.html">Google
                     using dubious tactics to target people with ‘darker skin’ in facial recognition project:
                     sources</a>
               </p>
            </td>
            <td><strong>Topic</strong>
               <p>
                  Housing Discrimination
               </p>
               <p>
                  <strong>Readings</strong>
               </p>
               <p>
                  <a href="https://themarkup.org/locked-out/2020/09/24/fair-housing-laws-algorithms-tenant-screenings">Can
                     Algorithms Violate Fair Housing Laws?</a>
               </p>
               <p>
                  <a href="http://faculty.haas.berkeley.edu/morse/research/papers/discrim.pdf">Consumer-Lending
                     Discrimination in the FinTech Era</a>
               </p>
               <p>
                  <a href="https://journals.library.columbia.edu/index.php/stlr/article/view/7963">Algorithms, Housing
                     Discrimination, and the New Disparate Impact Rule</a>
               </p>
               <p>
                  <strong><em>Post-Discussion Forum: *Optional*</em></strong>
               </p>
            </td>
         </tr>
      </tbody>
   </table>

</body>

</html>